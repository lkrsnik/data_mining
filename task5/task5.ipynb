{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import Orange\n",
      "from sklearn import metrics\n",
      "from scipy.optimize import fmin_l_bfgs_b\n",
      "\n",
      "def g(z):\n",
      "    return 1/(1+np.exp(-z))\n",
      "\n",
      "def add_ones(X):\n",
      "    return np.column_stack((np.ones(len(X)), X))\n",
      "\n",
      "def logloss(res):\n",
      "    ll = []\n",
      "    for i in range(res.probabilities.shape[0]):\n",
      "        # x je vektor verjetnosti, ki smo jih napovedali dejanskemu razredu\n",
      "        x = np.array([v[i] for v, i in zip(res.probabilities[i], res.actual.astype(int))])\n",
      "        ll.append(-sum(np.log(x))/len(x))\n",
      "    return ll"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class IO:\n",
      "    def read(fn, train=True):\n",
      "        X = np.genfromtxt(fn, delimiter = ',', usecols = np.arange(0, 93), skiprows = 1, dtype = float)\n",
      "        atts = [Orange.data.ContinuousVariable('x_' + str(num)) for num in range(93)]\n",
      "        class_var = Orange.data.DiscreteVariable('class_', values=[1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "        dbg_domain = Orange.data.Domain(attributes=atts, class_vars=class_var)\n",
      "        # converts first line into int and saves it\n",
      "        ids = X[:, 0].copy().astype(int)\n",
      "        # changes first line to ones\n",
      "        X[:, 0] = np.ones(X.shape[0])\n",
      "        if(train):\n",
      "            y = np.genfromtxt(fn, delimiter = ',', usecols = {94}, skiprows = 1, dtype = str)\n",
      "            # converts classes from string to float numbers\n",
      "            yn = np.zeros(len(y))\n",
      "            i = 0\n",
      "            for el in y:\n",
      "                yn[i] = float(el[6])\n",
      "                i += 1   \n",
      "            y = yn\n",
      "            return Orange.data.Table(dbg_domain, X, y)\n",
      "        else:\n",
      "            return X, ids\n",
      "    def write(res, ids):\n",
      "        fc = np.hstack((['id'], ids))\n",
      "        oc = np.vstack((['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9'], res))\n",
      "        sres = np.column_stack((fc, oc))\n",
      "        np.savetxt('results.csv', sres, delimiter=\",\", fmt=\"%s\") \n",
      "class NeuralNetClassifier(Orange.classification.Model):\n",
      "    \"\"\"Neural network classifier based on a set of binary classifiers.\"\"\"\n",
      "    def __init__(self, domain, thetas):\n",
      "        super().__init__(domain)\n",
      "        self.thetas = thetas  # model parameters\n",
      "    def predict(self, X):\n",
      "        return self.h(X, self.thetas)[-1]\n",
      "\n",
      "class NeuralNetLearner(Orange.classification.Learner):\n",
      "    def __init__(self, arch, lambda_=1e-5):\n",
      "        super().__init__()\n",
      "        self.arch = arch\n",
      "        self.lambda_ = lambda_\n",
      "        self.name = \"ann\"\n",
      "\n",
      "        self.theta_shape = np.array([(arch[i]+1, arch[i+1])\n",
      "                                     for i in range(len(arch)-1)])\n",
      "        ind = np.array([s1*s2 for s1, s2 in self.theta_shape])\n",
      "        self.theta_ind = np.cumsum(ind[:-1])\n",
      "        self.theta_len = sum(ind)\n",
      "\n",
      "    def init_thetas(self, epsilon=0.01):\n",
      "        return np.random.rand(self.theta_len) * 2 * epsilon - epsilon\n",
      "\n",
      "    def shape_thetas(self, thetas):\n",
      "        t = np.split(thetas, self.theta_ind)\n",
      "        return [t[i].reshape(shape) for i, shape in enumerate(self.theta_shape)]\n",
      "\n",
      "    def h(self, a, thetas):\n",
      "        \"\"\"feed forward, prediction\"\"\"\n",
      "        thetas = self.shape_thetas(thetas)\n",
      "        act = [a]\n",
      "        for theta in thetas:\n",
      "            a = g(add_ones(a).dot(theta))\n",
      "            act.append(a)\n",
      "        return act\n",
      "\n",
      "    def cost_grad(self, thetas, X, Y):\n",
      "        # use matrix and vector operations. could be written in a single line\n",
      "        # use self.m as stored by the fit function\n",
      "        ### COST ###\n",
      "        shaped_thetas = self.shape_thetas(thetas)\n",
      "        sumW = np.sum([np.sum(element[1:] ** 2) for element in shaped_thetas])\n",
      "        h = self.h(X, thetas)\n",
      "        cost = sum(sum((h[-1] - Y)**2)) / (2 * self.m) + ((self.lambda_ / (2 * self.m)) * sumW)\n",
      "        ### GRAD ###\n",
      "        pDelta = (-(Y - h[-1])) * (h[-1] * (1 - h[-1]))\n",
      "        grad = []\n",
      "        for theta, a in zip(reversed(shaped_thetas), reversed(h[:-1])):\n",
      "            delta = pDelta.dot(theta[1:].T) * (a * (1 - a))\n",
      "            theta[0] = np.zeros(theta.shape[1]).T\n",
      "            g = (add_ones(a).T.dot(pDelta) + (self.lambda_ * theta)) / self.m\n",
      "            grad = np.concatenate((g.flatten(), grad)) \n",
      "            pDelta = delta\n",
      "        return cost, grad\n",
      "\n",
      "    def grad_approx(self, thetas, X, Y, e=1e-1):\n",
      "        return np.array([(self.cost_grad(thetas+eps, X, Y)[0] - self.cost_grad(thetas-eps, X, Y)[0])/(2*e)\n",
      "                         for eps in np.identity(len(thetas)) * e])\n",
      "\n",
      "    def reshapeY(self, Y):\n",
      "        unique = np.unique(Y)\n",
      "        # elements with ones and zeros if calculation is for them\n",
      "        return np.array([np.array(Y == el).astype(float) for el in unique]).T\n",
      "        \n",
      "        \n",
      "    def cost_grad_test(self, init_theta, X, Y):\n",
      "        init_theta = self.init_thetas()\n",
      "        ng = self.grad_approx(init_theta, X, Y)\n",
      "        ag = self.cost_grad(init_theta, X, Y)[1]\n",
      "        print(np.sum((ag - ng)**2))\n",
      "        \n",
      "    def fit(self, X, y, W=None):\n",
      "        self.X, self.y = X, y\n",
      "        self.m = self.X.shape[0]\n",
      "        yn = self.reshapeY(y)\n",
      "        \n",
      "        thetas = self.init_thetas()\n",
      "        # METODA KONCNIH RAZLIK\n",
      "        print (\"cost_grad_test\")\n",
      "        #print (self.cost_grad_test(thetas, X, yn))\n",
      "\n",
      "        thetas, fmin, info = fmin_l_bfgs_b(self.cost_grad, thetas, args=(X, yn),\n",
      "                                           factr=10)\n",
      "\n",
      "        model = NeuralNetClassifier(self.domain, thetas)\n",
      "        model.h = self.h\n",
      "        return model\n",
      "\n",
      "    def test(self, a):\n",
      "        thetas = np.array([-30, 10, 20, -20, 20, -20, -10, 20, 20])\n",
      "        print(self.h(a, thetas))\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# LOAD DATA\n",
      "train = IO.read('train.csv')\n",
      "test, ids = IO.read('test.csv', False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IRIS TESTS\n",
      "iris = Orange.data.Table(\"iris\")\n",
      "class_var = Orange.data.DiscreteVariable('c', values=(i for i in range(len(iris.domain.class_var.values))))\n",
      "domain = Orange.data.Domain(iris.domain.attributes, class_var)\n",
      "data = Orange.data.Table(domain, iris.X, iris.Y)\n",
      "ann2 = NeuralNetLearner((4, 8, 3), lambda_=0.00001)\n",
      "res2 = Orange.evaluation.CrossValidation(data, [ann2], k=10)\n",
      "logloss(res2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cost_grad_test\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test\n",
        "cost_grad_test\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 128,
       "text": [
        "[0.41804469685729295]"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CROSS VALIDATION\n",
      "ann3 = NeuralNetLearner((93,20,9), lambda_=0.00001)\n",
      "res2 = Orange.evaluation.CrossValidation(train, [ann3], k=10)\n",
      "logloss(res2)\n",
      "# (93,20,9) - 2.3647389"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cost_grad_test\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost_grad_test"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "index 9 is out of bounds for axis 0 with size 9",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-98-c6dfa4de3763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mann3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m93\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mann3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-87-c94c9c2102cc>\u001b[0m in \u001b[0;36mlogloss\u001b[0;34m(res)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# x je vektor verjetnosti, ki smo jih napovedali dejanskemu razredu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-87-c94c9c2102cc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# x je vektor verjetnosti, ki smo jih napovedali dejanskemu razredu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: index 9 is out of bounds for axis 0 with size 9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# GET RESULTS\n",
      "ann = NeuralNetLearner((93,186,9), lambda_=0.00001)\n",
      "model = ann(train)\n",
      "res = model(test, ret=Orange.classification.Model.Probs)\n",
      "IO.write(res, ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}