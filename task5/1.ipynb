{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import Orange\n",
      "from scipy.optimize import fmin_l_bfgs_b\n",
      "\n",
      "def g(z):\n",
      "    return 1/(1+np.exp(-z))\n",
      "\n",
      "def add_ones(X):\n",
      "    return np.column_stack((np.ones(len(X)), X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuralNetClassifier(Orange.classification.Model):\n",
      "    \"\"\"Neural network classifier based on a set of binary classifiers.\"\"\"\n",
      "    def __init__(self, domain, thetas):\n",
      "        super().__init__(domain)\n",
      "        self.thetas = thetas  # model parameters\n",
      "    def predict(self, X):\n",
      "        return self.h(X, self.thetas)[-1]\n",
      "\n",
      "class NeuralNetLearner(Orange.classification.Learner):\n",
      "    def __init__(self, arch, lambda_=1e-5):\n",
      "        super().__init__()\n",
      "        self.arch = arch\n",
      "        self.lambda_ = lambda_\n",
      "        self.name = \"ann\"\n",
      "\n",
      "        self.theta_shape = np.array([(arch[i]+1, arch[i+1])\n",
      "                                     for i in range(len(arch)-1)])\n",
      "        ind = np.array([s1*s2 for s1, s2 in self.theta_shape])\n",
      "        self.theta_ind = np.cumsum(ind[:-1])\n",
      "        self.theta_len = sum(ind)\n",
      "\n",
      "    def init_thetas(self, epsilon=0.01):\n",
      "        return np.random.rand(self.theta_len) * 2 * epsilon - epsilon\n",
      "\n",
      "    def shape_thetas(self, thetas):\n",
      "        t = np.split(thetas, self.theta_ind)\n",
      "        return [t[i].reshape(shape) for i, shape in enumerate(self.theta_shape)]\n",
      "\n",
      "    def h(self, a, thetas):\n",
      "        \"\"\"feed forward, prediction\"\"\"\n",
      "        thetas = self.shape_thetas(thetas)\n",
      "        act = [a]\n",
      "        for theta in thetas:\n",
      "            act.append(g(add_ones(a).dot(theta)))\n",
      "        return act\n",
      "\n",
      "    def cost_grad(self, thetas, X, Y):\n",
      "        # use matrix and vector operations. could be written in a single line\n",
      "        # use self.m as stored by the fit function\n",
      "        # ---------------------------------------- COST ------------------------------\n",
      "\n",
      "\n",
      "        a = []\n",
      "        shaped_thetas = self.shape_thetas(thetas)\n",
      "        #W = [theta[1:] for theta in shaped_thetas]\n",
      "        sumW = np.sum([np.sum(element[1:] ** 2) for element in shaped_thetas])\n",
      "        h = self.h(X, thetas)\n",
      "        \n",
      "        \n",
      "        \"\"\"#################### TEST ######################\n",
      "        \n",
      "        h[-1] = np.array([[ 0.5022720987261475,  0.4977279012738524],\n",
      "       [ 0.5022706722198477,  0.4977293277801524],\n",
      "       [ 0.502266267528223 ,  0.497733732471777 ],\n",
      "       [ 0.502264841137491 ,  0.497735158862509 ]])\n",
      "        \n",
      "        ################################################\"\"\"\n",
      "        cost = sum(sum((h[-1] - Y)**2)) / (2 * self.m) + ((self.lambda_ / 2) * sumW)\n",
      "        \n",
      "        return cost\n",
      "        \n",
      "        # ---------------------------------------- GRAD ------------------------------\n",
      "        \n",
      "        de = []\n",
      "        pDelta = (-(Y - h[-1])) #* (h[-1] * (1 - h[-1]))\n",
      "        de.append(pDelta)\n",
      "        \n",
      "\n",
      "        grad = []\n",
      "        for theta, a in zip(reversed(shaped_thetas), reversed(h[:-1])):\n",
      "            delta = pDelta.dot(theta[1:].T) * (a * (1 - a))\n",
      "            #print (delta)\n",
      "            de.append(delta)\n",
      "            #works ^^\n",
      "            #print (add_ones(a).T)\n",
      "            #print (add_ones(a).T.dot(pDelta).flatten())\n",
      "            grad = np.concatenate((add_ones(a).T.dot(pDelta).flatten(), grad))\n",
      "            pDelta = delta\n",
      "            #print (a)\n",
      "            #print (delta)\n",
      "        #grad = np.concatenate((add_ones(a).T.dot(pDelta).flatten(), grad))\n",
      "        regGrad = np.sum([np.sum(element[1:]) for element in shaped_thetas])\n",
      "        grad = (1 / self.m) * grad + (self.lambda_) * regGrad\n",
      "        #print (cost)\n",
      "        #print (np.array(grad))\n",
      "        return cost, grad\n",
      "\n",
      "    def grad_approx(self, thetas, X, Y, e=1e-1):\n",
      "        return np.array([(self.cost_grad(thetas+eps, X, Y)[0] - self.cost_grad(thetas-eps, X, Y)[0])/(2*e)\n",
      "                         for eps in np.identity(len(thetas)) * e])\n",
      "\n",
      "    def reshapeY(self, Y):\n",
      "        unique = np.unique(Y)\n",
      "        # elements with ones and zeros if calculation is for them\n",
      "        return np.array([np.array(y == el).astype(float) for el in unique])[-1]\n",
      "        \n",
      "        \n",
      "    def cost_grad_test(self, init_theta, X, Y):\n",
      "        init_theta = ann.init_thetas()\n",
      "        ng = self.grad_approx(init_theta, X, Y)\n",
      "        ag = self.cost_grad(init_theta, X, Y)[1]\n",
      "        print(np.sum((ag - ng)**2))\n",
      "        \n",
      "    def fit(self, X, y, W=None):\n",
      "        self.X, self.y = X, y\n",
      "        self.m = self.X.shape[0]\n",
      "        yn = self.reshapeY(y)\n",
      "        \n",
      "        thetas = self.init_thetas()\n",
      "        \n",
      "        print (\"cost_grad_test\")\n",
      "        print (self.cost_grad_test(thetas, X, yn))\n",
      "        print (\"--------------\")\n",
      "        \n",
      "        # y reshapi namesto kasneje; VRZI VN factr\n",
      "        thetas, fmin, info = fmin_l_bfgs_b(self.cost_grad, thetas, args=(X, yn),\n",
      "                                           #callback=self.callback,\n",
      "                                           factr=10)\n",
      "\n",
      "        model = NeuralNetClassifier(self.domain, thetas)\n",
      "        model.h = self.h\n",
      "        return model\n",
      "\n",
      "    def test(self, a):\n",
      "        thetas = np.array([-30, 10, 20, -20, 20, -20, -10, 20, 20])\n",
      "        print(self.h(a, thetas))\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ann = NeuralNetLearner((2,2,2), lambda_=0.0001)\n",
      "model = ann(xor_data)\n",
      "model(xor_data.X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'xor_data' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-5971dcda2c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxor_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'xor_data' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "############# TEST - PRIMERJAVA ROK ################\n",
      "ann = NeuralNetLearner((2,2,2), lambda_=0.0001)\n",
      "thetas = np.array([ 0.0082606739529037,  0.0081071402188289,  0.0079277809121003,\n",
      "  0.0079170015261919 , 0.0073259586599964, -0.0031888699995852,\n",
      "  0.0054305278343758, -0.0095707870220028, -0.000049810920116,\n",
      "  0.0056928340725427, -0.0006569332182566,  0.0053779549434834])\n",
      "X = np.array([[ 0.,  0.],\n",
      " [ 0.,  1.],\n",
      " [ 1.,  0.],\n",
      " [ 1.,  1.]])\n",
      "y = np.array([[ 1.,  0.],\n",
      " [ 0.,  1.],\n",
      " [ 0.,  1.],\n",
      " [ 1.,  0.]])\n",
      "ann.m = X.shape[0]\n",
      "cost = ann.cost_grad(thetas, X, y)\n",
      "#cost = ann.cost_grad(np.zeros(data.Y.shape[1]), data.X, data.Y)\n",
      "cost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 209,
       "text": [
        "(0.25000181144641009,\n",
        " array([  2.66972454e-06,   2.64334928e-06,   2.97662812e-06,\n",
        "         2.95994027e-06,   2.96955739e-06,   2.95215541e-06,\n",
        "         3.20354577e-04,  -2.49650566e-04,   1.62938061e-04,\n",
        "        -1.23983705e-04,   1.62530763e-04,  -1.23858981e-04]))"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuralNetClassifier(Orange.classification.Model):\n",
      "    \"\"\"Neural network classifier based on a set of binary classifiers.\"\"\"\n",
      "    def __init__(self, domain, thetas):\n",
      "        super().__init__(domain)\n",
      "        self.thetas = thetas  # model parameters\n",
      "\n",
      "    def predict(self, X):\n",
      "        y_hat = np.ravel(self.h(X, self.thetas))\n",
      "        # following works only for binary classifiers, correct it for multiclass\n",
      "        return np.vstack((1-y_hat, y_hat)).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = Orange.data.Table(\"xor\")\n",
      "ann.m = data.X.shape[0]\n",
      "np.random.seed(42)\n",
      "train, test = Orange.evaluation.sample(data, 5)\n",
      "ann = NeuralNetLearner((2, 2, 2), lambda_=0.1)\n",
      "model = ann(xor_data)\n",
      "model(xor_data.X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cost_grad_test\n",
        "3.06021741446e-06\n",
        "None\n",
        "--------------\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 291,
       "text": [
        "array([0, 0, 1, 1])"
       ]
      }
     ],
     "prompt_number": 291
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = Orange.evaluation.CrossValidation(data, [ann], k=5)\n",
      "print(Orange.evaluation.AUC(res))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "operands could not be broadcast together with shapes (39,2) (4,2) ",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-240-fdd5b69d521f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOrange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/luka/Documents/Programs/orange3/Orange/evaluation/testing.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, learners, k, random_state, store_data, store_models)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0mfold_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/luka/Documents/Programs/orange3/Orange/classification/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_multiclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_multiclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-205-9e22a5f68f47>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, W)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"cost_grad_test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_grad_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-205-9e22a5f68f47>\u001b[0m in \u001b[0;36mcost_grad_test\u001b[0;34m(self, init_theta, X, Y)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcost_grad_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0minit_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_thetas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-205-9e22a5f68f47>\u001b[0m in \u001b[0;36mgrad_approx\u001b[0;34m(self, thetas, X, Y, e)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         return np.array([(self.cost_grad(thetas+eps, X, Y)[0] - self.cost_grad(thetas-eps, X, Y)[0])/(2*e)\n\u001b[0;32m---> 83\u001b[0;31m                          for eps in np.identity(len(thetas)) * e])\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreshapeY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-205-9e22a5f68f47>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         return np.array([(self.cost_grad(thetas+eps, X, Y)[0] - self.cost_grad(thetas-eps, X, Y)[0])/(2*e)\n\u001b[0;32m---> 83\u001b[0;31m                          for eps in np.identity(len(thetas)) * e])\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreshapeY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-205-9e22a5f68f47>\u001b[0m in \u001b[0;36mcost_grad\u001b[0;34m(self, thetas, X, Y)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m################################################\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msumW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# ---------------------------------------- GRAD ------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (39,2) (4,2) "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cost_grad_test\n"
       ]
      }
     ],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "atts = [Orange.data.ContinuousVariable('x1'), Orange.data.ContinuousVariable('x2')]\n",
      "class_var = Orange.data.DiscreteVariable('Class_1', values=(0, 1))\n",
      "dbg_domain = Orange.data.Domain(attributes=atts, class_vars=class_var)\n",
      "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
      "and_data = Orange.data.Table(dbg_domain, X, np.array([0]*3+[1]).T)\n",
      "xor_data = Orange.data.Table(dbg_domain, X, np.array([0]+[1]*2+[0]).T)\n",
      "xor_arch = (2,2,2)\n",
      "xor_thetas = np.array([-30, 10, 20, -20, 20, -20, 10, -20, -20])\n",
      "print (and_data)\n",
      "print (xor_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0.000, 0.000 | 0],\n",
        " [0.000, 1.000 | 0],\n",
        " [1.000, 0.000 | 0],\n",
        " [1.000, 1.000 | 1]\n",
        "[[0.000, 0.000 | 0],\n",
        " [0.000, 1.000 | 1],\n",
        " [1.000, 0.000 | 1],\n",
        " [1.000, 1.000 | 0]\n"
       ]
      }
     ],
     "prompt_number": 142
    }
   ],
   "metadata": {}
  }
 ]
}