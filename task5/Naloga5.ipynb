{
 "metadata": {
  "name": "",
  "signature": "sha256:1661cd2eda00984197f4f3cdd621bca0b677673050d4851e46f8cf8ab06ff811"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import Orange\n",
      "from scipy.optimize import fmin_l_bfgs_b\n",
      "def g(z):\n",
      "    return 1/(1+np.exp(-z))\n",
      "\n",
      "def add_ones(X):\n",
      "    return np.column_stack((np.ones(len(X)), X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#prepare train data\n",
      "data_X = np.loadtxt(\"train.csv\", delimiter=\",\", skiprows=1, usecols=(range(0,94)))\n",
      "data_id = data_X[:,0]\n",
      "data_X = data_X[:,1:data_X.shape[0]]\n",
      "data_YY = np.loadtxt(\"train.csv\", delimiter=\",\", dtype= np.dtype(str), skiprows=1, usecols=(range(94, 95)))\n",
      "counter = 0;\n",
      "data_Y=np.zeros(data_YY.shape[0])\n",
      "for i in data_YY:\n",
      "    data_Y[counter] = int(i[8])-1\n",
      "    counter = counter+1\n",
      "#preapare test data\n",
      "test_X = np.loadtxt(\"test.csv\", delimiter=\",\", skiprows=1)\n",
      "test_id = test_X[:,0]\n",
      "print(test_X.shape[0])\n",
      "test_X = test_X[:,1:test_X.shape[0]]\n",
      "print(data_X.shape)\n",
      "print(data_Y.shape)\n",
      "print(data_id.shape)\n",
      "print(test_X.shape)\n",
      "print(test_id.shape)\n",
      "#prepare for orange\n",
      "feature_name = np.linspace(1,93,93)\n",
      "feature_list = [Orange.data.ContinuousVariable(str(k)) for k in feature_name]  \n",
      "class_var = Orange.data.DiscreteVariable(\"class\", values=[0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "domain = Orange.data.Domain(feature_list, class_var)\n",
      "data = Orange.data.Table(domain, data_X, data_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11878\n",
        "(50000, 93)\n",
        "(50000,)\n",
        "(50000,)\n",
        "(11878, 93)\n",
        "(11878,)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Naloga 5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuralNetLearner(Orange.classification.Learner):\n",
      "    def __init__(self, arch, domain, lambda_=1e-5):\n",
      "        super().__init__()\n",
      "        self.arch = arch\n",
      "        self.lambda_ = lambda_\n",
      "        self.name = \"ann\"\n",
      "        self.domain = domain\n",
      "        self.theta_shape = np.array([(arch[i]+1, arch[i+1])\n",
      "                                     for i in range(len(arch)-1)])\n",
      "        ind = np.array([s1*s2 for s1, s2 in self.theta_shape])\n",
      "        self.theta_ind = np.cumsum(ind[:-1])\n",
      "        self.theta_len = sum(ind)\n",
      "\n",
      "    def init_thetas(self, epsilon=1):\n",
      "        return np.random.rand(self.theta_len) * 2 * epsilon - epsilon\n",
      "\n",
      "    def shape_thetas(self, thetas):\n",
      "        t = np.split(thetas, self.theta_ind)\n",
      "        return [t[i].reshape(shape) for i, shape in enumerate(self.theta_shape)]\n",
      "\n",
      "    def h(self, a, thetas):\n",
      "        \"\"\"feed forward, prediction\"\"\"\n",
      "        thetas = self.shape_thetas(thetas)\n",
      "        for theta in thetas:\n",
      "            a = g(add_ones(a).dot(theta))\n",
      "        return a\n",
      "\n",
      "    def J(self, thetas):\n",
      "        # use matrix and vector operations. could be written in a single line\n",
      "        # use self.m as stored by the fit function\n",
      "        #print(self.y)\n",
      "        m = self.m\n",
      "        regularization = 0\n",
      "        shapethetas = self.shape_thetas(thetas)\n",
      "        #for all levels\n",
      "        \n",
      "        for i in shapethetas:\n",
      "            #remove bias            \n",
      "            x = np.delete(i, (0), axis=0)            \n",
      "            #for all elements add vectorTHETA^2\n",
      "            x = x**2\n",
      "            regularization+=sum(sum(x))\n",
      "    \n",
      "        error = (self.h(self.X, thetas) - self.ymatrix) \n",
      "        #print(error)\n",
      "        error = error.flatten()\n",
      "        cost = ((1/(2))* error.dot(error)) #+ ((self.lambda_ / (2*m))* regularization)\n",
      "        #print(cost)\n",
      "        return cost\n",
      "    \n",
      "    def fastCostGrad(self, thetas):\n",
      "        m = self.m\n",
      "        regCost = 0;\n",
      "        regGrad = 0;\n",
      "        shapethetas = self.shape_thetas(thetas)\n",
      "        for i in shapethetas:\n",
      "            #remove bias            \n",
      "            x = np.delete(i, (0), axis=0)            \n",
      "            #for all elements add vectorTHETA^2\n",
      "            regGrad+=sum(sum(x))\n",
      "            x = x**2\n",
      "            regCost+=sum(sum(x))\n",
      "        \n",
      "        #------------------grad---------------------\n",
      "        #izracunaj aktivacijo za vse nivoje\n",
      "        activations = []\n",
      "        activations.append(self.X);\n",
      "        a = self.X\n",
      "        for theta in shapethetas:\n",
      "            a = g(add_ones(a).dot(theta))\n",
      "            activations.append(a) \n",
      "        feedForward = a;\n",
      "        activationsLast = a;\n",
      "        \n",
      "        #aktivacija za zadnji nivo\n",
      "        activationsLast = a\n",
      "        a = -(self.ymatrix - activationsLast) \n",
      "        b = activationsLast * ( 1-activationsLast)\n",
      "        delta = a*b\n",
      "        #delta = delta[:, None]\n",
      "        \n",
      "        #izracunaj delte za vse nivoje\n",
      "        res = delta.T.dot(add_ones(activations[1])).T\n",
      "        rezultat = res.flatten()\n",
      "        for i in reversed(range(1, len(activations)-1)):\n",
      "            thetasCurrent = shapethetas[i]            \n",
      "            a = delta.dot(thetasCurrent[1:].T);\n",
      "            b = activations[i]*(1-activations[i])   \n",
      "            delta = a*b\n",
      "            res = (delta.T.dot(add_ones(activations[i-1]))).T\n",
      "            rezultat = np.append(res.flatten(), rezultat)\n",
      "        grad = (rezultat/m) + ((self.lambda_/m) * regGrad) \n",
      "        \n",
      "        #------------------cost---------------------\n",
      "        error = (feedForward - self.ymatrix) \n",
      "        error = error.flatten()\n",
      "        cost = ((1/(m*2))* error.dot(error)) + ((self.lambda_ / (2*m))* regCost)\n",
      "        return cost, grad\n",
      "        \n",
      "    \n",
      "    def grad_approx(self, thetas, e=1e-4):\n",
      "        return np.array([(self.J(thetas+eps) - self.J(thetas-eps))/(2*e)\n",
      "                         for eps in np.identity(len(thetas)) * e])\n",
      "\n",
      "    def backprop(self, thetas):\n",
      "        \n",
      "        #izracunaj aktivacijo za vse nivoje\n",
      "        activations = []\n",
      "        activations.append(self.X);\n",
      "        thetas_reshaped = self.shape_thetas(thetas)\n",
      "        a = self.X\n",
      "        for theta in thetas_reshaped:\n",
      "            a = g(add_ones(a).dot(theta))\n",
      "            activations.append(a)      \n",
      "           \n",
      "        #aktivacija za zadnji nivo\n",
      "        activationsLast = a\n",
      "        a = -(self.ymatrix - activationsLast) \n",
      "        b = np.prod([activationsLast, ( 1-activationsLast)], axis=0)\n",
      "        delta = np.prod([a, b], axis = 0)\n",
      "        #delta = delta[:, None]\n",
      "        \n",
      "        #izracunaj delte za vse nivoje\n",
      "        res = delta.T.dot(add_ones(activations[1])).T\n",
      "        rezultat = res.flatten()\n",
      "\n",
      "        for i in reversed(range(1, len(activations)-1)):\n",
      "            thetasCurrent = thetas_reshaped[i]            \n",
      "            a = delta.dot(thetasCurrent[1:].T);\n",
      "            b = activations[i]*(1-activations[i])   \n",
      "            delta = a*b\n",
      "            res = (delta.T.dot(add_ones(activations[i-1]))).T\n",
      "            rezultat = np.append(res.flatten(), rezultat)\n",
      "            \n",
      "        m = self.m\n",
      "        regularization = 0\n",
      "        \n",
      "        #for all levels\n",
      "        for i in thetas_reshaped:\n",
      "            #remove bias\n",
      "            x = np.delete(i, (0), axis=0)\n",
      "            regularization+=sum(sum(x)) \n",
      "        return (rezultat/m) + ((self.lambda_/m) * regularization)             \n",
      "\n",
      "    def numerical_test(self, thetas):\n",
      "        ng = self.grad_approx(thetas)\n",
      "        print(\"APPROX\")\n",
      "        print(ng)\n",
      "        ag = self.fastCostGrad(thetas)[1]\n",
      "        print(\"BACKPROP\")\n",
      "        print(ag)\n",
      "        print(\"NAPAKA PRI GRADIENTU\")\n",
      "        print(np.sum((ag - ng)**2))\n",
      "        \n",
      "\n",
      "    def fit(self, X, y, W=None):\n",
      "        yUniq = np.unique(y)\n",
      "        print(yUniq)\n",
      "        ynew = np.eye(len(yUniq))[y.astype(int)]\n",
      "        self.ymatrix = ynew\n",
      "        self.X, self.y = X, y\n",
      "        self.m = self.X.shape[0]\n",
      "        thetas = self.init_thetas()\n",
      "        #self.J(thetas)\n",
      "        #self.backprop(thetas)\n",
      "        #self.numerical_test(thetas)\n",
      "        #print(\"FMINLBFGSB\")\n",
      "        thetas, fmin, info = fmin_l_bfgs_b(self.J, thetas, self.backprop,\n",
      "                                           factr=10)\n",
      "        #thetas, fmin, info = fmin_l_bfgs_b(self.fastCostGrad, thetas, factr=10)\n",
      "        print(\"USPELO\")\n",
      "        model = NeuralNetClassifier(self.domain, thetas)\n",
      "        model.h = self.h\n",
      "        return model\n",
      "\n",
      "    def test(self, a):\n",
      "        thetas = np.array([-30, 10, 20, -20, 20, -20, -10, 20, 20])\n",
      "        print(self.h(a, thetas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ann = NeuralNetLearner(xor_arch, None, lambda_=0.1)\n",
      "ann.X, ann.y = xor_data.X, xor_data.Y\n",
      "ann.m = ann.X.shape[0]\n",
      "y = ann.y\n",
      "yUniq = np.unique(y)\n",
      "print(yUniq)\n",
      "ynew = np.eye(len(yUniq))[y.astype(int)]\n",
      "ann.ymatrix = ynew\n",
      "cost = ann.J(xor_thetas)\n",
      "#cost = ann.cost_grad(np.zeros(data.Y.shape[1]), data.X, data.Y)\n",
      "cost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  1.]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "1.9998181692995911"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "atts = [Orange.data.ContinuousVariable('x1'), Orange.data.ContinuousVariable('x2')]\n",
      "class_var = Orange.data.DiscreteVariable('Class_1', values=(0, 1))\n",
      "dbg_domain = Orange.data.Domain(attributes=atts, class_vars=class_var)\n",
      "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
      "and_data = Orange.data.Table(dbg_domain, X, np.array([0]*3+[1]).T)\n",
      "xor_data = Orange.data.Table(dbg_domain, X, np.array([0]+[1]*2+[0]).T)\n",
      "xor_arch = (2,2,1)\n",
      "xor_thetas = np.array([-30, 10, 20, -20, 20, -20, 10, -20, -20])\n",
      "print (and_data)\n",
      "print (xor_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0.000, 0.000 | 0],\n",
        " [0.000, 1.000 | 0],\n",
        " [1.000, 0.000 | 0],\n",
        " [1.000, 1.000 | 1]\n",
        "[[0.000, 0.000 | 0],\n",
        " [0.000, 1.000 | 1],\n",
        " [1.000, 0.000 | 1],\n",
        " [1.000, 1.000 | 0]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuralNetClassifier(Orange.classification.Model):\n",
      "    \"\"\"Neural network classifier based on a set of binary classifiers.\"\"\"\n",
      "    def __init__(self, domain, thetas):\n",
      "        super().__init__(domain)\n",
      "        self.thetas = thetas  # model parameters\n",
      "\n",
      "    def predict(self, X):\n",
      "        y_hat = self.h(X, self.thetas)\n",
      "        #print(y_hat)\n",
      "        # following works only for binary classifiers, correct it for multiclass\n",
      "        return y_hat\n",
      "        #return np.vstack((1-y_hat, y_hat)).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "##TEST DATA \n",
      "atts = [Orange.data.ContinuousVariable('x1'), Orange.data.ContinuousVariable('x2')]\n",
      "class_var = Orange.data.DiscreteVariable('Class_1', values=(0, 1))\n",
      "dbg_domain = Orange.data.Domain(attributes=atts, class_vars=class_var)\n",
      "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
      "and_data = Orange.data.Table(dbg_domain, X, np.array([0]*3+[1]).T)\n",
      "xor_data = Orange.data.Table(dbg_domain, X, np.array([0]+[1]*2+[0]).T)\n",
      "xor_arch = (2,2,1)\n",
      "xor_thetas = np.array([-30, 10, 20, -20, 20, -20, 10, -20, -20])\n",
      "and_data\n",
      "ann = NeuralNetLearner((xor_data.X.shape[1], 8, 2), dbg_domain, lambda_=0.0000001)\n",
      "th = ann.init_thetas()\n",
      "print(th)\n",
      "#yUniq = np.unique(xor_data.Y)\n",
      "#y = np.eye(len(yUniq))[xor_data.Y.astype(int)]\n",
      "#print(y)\n",
      "model = ann.fit(xor_data.X, xor_data.Y)\n",
      "res = model(xor_data, ret=Orange.classification.Model.Probs)\n",
      "print(res)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.4218692188721584 -0.5666289827462001 -0.9239646025188675\n",
        "  0.3787788456729848 -0.8712567521680541  0.2510589908603411\n",
        "  0.9412941137886057 -0.2643512257733318 -0.8016283383617782\n",
        " -0.2539035104894962  0.7150524585322575 -0.8699309951407943\n",
        " -0.4277079119258256 -0.5124413018706886 -0.7718439072671239\n",
        " -0.9411128401435243  0.8061583569997912  0.2398385905088043\n",
        " -0.6949067151873471 -0.5059171541770564 -0.563445970006677\n",
        "  0.2669569541211259 -0.1005243661116548  0.8716731013754142\n",
        "  0.1224235682936063  0.991672001906476   0.6050430684838555\n",
        "  0.7131838141668252 -0.8024029050172865 -0.7490198839201287\n",
        "  0.1417643279739849 -0.7437328147041147 -0.277868711478366\n",
        " -0.0684048422026122 -0.0780563013379751 -0.6608369920714805\n",
        "  0.9019866017109204  0.4569031891875655 -0.1321398524497772\n",
        " -0.5015311225484622  0.8942732036305467  0.1993067731616487]\n",
        "[ 0.  1.]\n",
        "USPELO\n",
        "[[ 0.9979774019679094  0.0000680818595517]\n",
        " [ 0.0062061621232789  0.9983736014769504]\n",
        " [ 0.0000220474439365  0.999930284235183 ]\n",
        " [ 0.9950460815421406  0.0010256334824784]]\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "iris = Orange.data.Table(\"iris\")\n",
      "class_var = Orange.data.DiscreteVariable('Class_1', values=(i for i in range(len(iris.domain.class_var.values))))\n",
      "iris_dbg_domain = Orange.data.Domain(iris.domain.attributes, class_var)\n",
      "iris_dbg_data = Orange.data.Table(iris_dbg_domain, iris.X, iris.Y)\n",
      "ann = NeuralNetLearner((iris_dbg_data.X.shape[1], 9, 3), iris_dbg_domain, lambda_=0.1)\n",
      "#print(y)\n",
      "model = ann.fit(iris_dbg_data.X, iris_dbg_data.Y)\n",
      "r = model(iris_dbg_data, ret=Orange.classification.Model.Probs)\n",
      "#print(iris_dbg_data.Y.shape)\n",
      "r\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  1.  2.]\n",
        "USPELO"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "array([[ 0.9964121486067212,  0.02316683439228  ,  0.0000197126913275],\n",
        "       [ 0.9949344087829999,  0.0319914291800964,  0.0000288054196137],\n",
        "       [ 0.9961731186296975,  0.0247784562732825,  0.0000212629314409],\n",
        "       [ 0.9946347624668248,  0.0338787987307862,  0.0000301591343425],\n",
        "       [ 0.9965618205052046,  0.0223291315172142,  0.0000188596043294],\n",
        "       [ 0.9960498026999273,  0.0253299082974817,  0.0000217490883978],\n",
        "       [ 0.9961278951205237,  0.0252504630170921,  0.0000215361850169],\n",
        "       [ 0.9959045103182276,  0.0262620182223011,  0.000022785548845 ],\n",
        "       [ 0.9942751463934705,  0.0360049165821572,  0.000032144249692 ],\n",
        "       [ 0.9950305786781637,  0.0314413356641714,  0.0000282743632848],\n",
        "       [ 0.9964570988198227,  0.0227986838085368,  0.0000193637249866],\n",
        "       [ 0.9954032216509223,  0.0293448040822988,  0.0000256747119056],\n",
        "       [ 0.9952715802073274,  0.030033933414071 ,  0.0000267829082369],\n",
        "       [ 0.9965060550190977,  0.0229879912263912,  0.0000195358575737],\n",
        "       [ 0.9969306301289782,  0.0197986578481483,  0.0000163505278495],\n",
        "       [ 0.9969005575059866,  0.0201147753940868,  0.0000166674002039],\n",
        "       [ 0.9968137002621219,  0.0207066296541692,  0.0000172604034169],\n",
        "       [ 0.9963071391457228,  0.0238342379330866,  0.0000203411789901],\n",
        "       [ 0.9959217328931196,  0.0259888898375545,  0.0000226449482046],\n",
        "       [ 0.9965411800059928,  0.0224769154019701,  0.0000189642922287],\n",
        "       [ 0.9945948131189174,  0.0339307421907695,  0.000031140239486 ],\n",
        "       [ 0.9962792116318573,  0.0240774290917311,  0.0000204798452576],\n",
        "       [ 0.9969983854258948,  0.0199867202370209,  0.0000166506885902],\n",
        "       [ 0.9913251114487738,  0.0521013365668578,  0.0000486676822279],\n",
        "       [ 0.991447180756865 ,  0.0516126149241796,  0.0000479294593147],\n",
        "       [ 0.9924753645606413,  0.0460883643614253,  0.000044228116713 ],\n",
        "       [ 0.9946721659345404,  0.0335322082069175,  0.0000297452283327],\n",
        "       [ 0.9961280873878706,  0.0248457246487374,  0.0000214173332957],\n",
        "       [ 0.9962223446910942,  0.0242608410988322,  0.000020851559034 ],\n",
        "       [ 0.9942946528958141,  0.03580509901012  ,  0.000032125327429 ],\n",
        "       [ 0.9935035655435521,  0.0402765198424437,  0.0000371078444916],\n",
        "       [ 0.995411753394491 ,  0.0290893618002537,  0.000025777686833 ],\n",
        "       [ 0.9968744092299663,  0.0203615004120511,  0.0000169304238446],\n",
        "       [ 0.9969284670043836,  0.0199368099482662,  0.0000165022940323],\n",
        "       [ 0.9950305786781637,  0.0314413356641714,  0.0000282743632848],\n",
        "       [ 0.996407400817978 ,  0.0231872100872143,  0.0000197680336499],\n",
        "       [ 0.9965519437274256,  0.0221634949185501,  0.0000187526490116],\n",
        "       [ 0.9950305786781637,  0.0314413356641714,  0.0000282743632848],\n",
        "       [ 0.9956131279896158,  0.0282871490681318,  0.0000245692254411],\n",
        "       [ 0.9958920601300111,  0.0262935047299932,  0.0000228701284721],\n",
        "       [ 0.9965416913781771,  0.0224699650114575,  0.000018992211623 ],\n",
        "       [ 0.9852550462521625,  0.0828126193652699,  0.0000852278297151],\n",
        "       [ 0.9961907903485592,  0.0249384657837461,  0.0000213014979396],\n",
        "       [ 0.9942535822681106,  0.0359287951255055,  0.0000314110577178],\n",
        "       [ 0.9942485568669466,  0.0359336196946623,  0.0000316930764925],\n",
        "       [ 0.9945272918836137,  0.0343856819111749,  0.0000309578045046],\n",
        "       [ 0.9964246828160339,  0.0231439075672367,  0.0000196318577557],\n",
        "       [ 0.9957796047401807,  0.0272046359465261,  0.000023558009743 ],\n",
        "       [ 0.9964697074819139,  0.0227594053316959,  0.0000193093969896],\n",
        "       [ 0.9960289512044046,  0.0254970193496951,  0.0000220583562475],\n",
        "       [ 0.0520231255083586,  0.9606185562087527,  0.0218626114908043],\n",
        "       [ 0.0362766043095125,  0.9447707734474791,  0.031043384350466 ],\n",
        "       [ 0.027643369283563 ,  0.9288360953724548,  0.0378236329283329],\n",
        "       [ 0.0069771727922986,  0.7692121798653527,  0.1112416144305281],\n",
        "       [ 0.0171461879362574,  0.8875629908220252,  0.0526865914478346],\n",
        "       [ 0.0059685308721766,  0.7771770815369863,  0.1806886089792981],\n",
        "       [ 0.0180057932028602,  0.9033948646819953,  0.0668419903171503],\n",
        "       [ 0.0423630707313617,  0.9462390206121678,  0.0240647793443687],\n",
        "       [ 0.0363944954029299,  0.9431755599679116,  0.0284262714902165],\n",
        "       [ 0.0098823939375883,  0.8315629558830278,  0.1039713267386485],\n",
        "       [ 0.0166145055629309,  0.8713327103461426,  0.0458756280036117],\n",
        "       [ 0.0252745824936381,  0.9217266162433905,  0.0422184179419554],\n",
        "       [ 0.0345542004781216,  0.9329928044461212,  0.0239519178552591],\n",
        "       [ 0.0074847690599527,  0.8082414159786581,  0.1424527599041479],\n",
        "       [ 0.0547876880377476,  0.9605303536481195,  0.0206267921502279],\n",
        "       [ 0.0532483846057324,  0.9608370280606416,  0.0209634293470622],\n",
        "       [ 0.0034746384076185,  0.6930766315857079,  0.3071511445299082],\n",
        "       [ 0.0421814672726984,  0.9507849046788809,  0.0259650703062563],\n",
        "       [ 0.0018426731738127,  0.5082648261468578,  0.3025520249473175],\n",
        "       [ 0.0321731798465715,  0.9331096351666971,  0.0298970111905768],\n",
        "       [ 0.0010440430133227,  0.4545748556948928,  0.6322319551305203],\n",
        "       [ 0.0475292758782988,  0.9543290479512234,  0.0217893962994252],\n",
        "       [ 0.0008923535246651,  0.3875657849351775,  0.5614938692756283],\n",
        "       [ 0.011757392724536 ,  0.86236811286616  ,  0.0927463746507043],\n",
        "       [ 0.0460007205589618,  0.9539570745318212,  0.0230274151464711],\n",
        "       [ 0.0467206070464788,  0.9547464045289049,  0.0227405029923284],\n",
        "       [ 0.0223175626214351,  0.910353228988143 ,  0.041394849109805 ],\n",
        "       [ 0.0049138626951768,  0.7381835922991874,  0.1870590488207079],\n",
        "       [ 0.0091581006618267,  0.8286689605700155,  0.1121522934843299],\n",
        "       [ 0.0621871732811735,  0.9649796838917825,  0.0182401785431673],\n",
        "       [ 0.0298518773782167,  0.9266625364757554,  0.0305743236405173],\n",
        "       [ 0.0414587853814706,  0.9461495155980559,  0.0234040420635234],\n",
        "       [ 0.0433465693464634,  0.9500191225368506,  0.0237563829526388],\n",
        "       [ 0.0001770598435226,  0.1487569179233241,  0.9052354858561487],\n",
        "       [ 0.0017007790066786,  0.5580380800560576,  0.5130367460070662],\n",
        "       [ 0.0219681304708234,  0.9189492347630172,  0.0586068378074508],\n",
        "       [ 0.0318784983001942,  0.936841982160589 ,  0.0331152835540376],\n",
        "       [ 0.0121523074524331,  0.8402287205580343,  0.0590204566876395],\n",
        "       [ 0.030221793819569 ,  0.9351004695161338,  0.0387436797800778],\n",
        "       [ 0.0121867734077736,  0.8503407759708141,  0.0734161352779279],\n",
        "       [ 0.0040257176447024,  0.7088849867015952,  0.2422120320829859],\n",
        "       [ 0.0146720969119046,  0.8836964906533186,  0.0765753431655015],\n",
        "       [ 0.0330311683792179,  0.9348638651161144,  0.0291725178967959],\n",
        "       [ 0.0417737106942062,  0.9443692048723217,  0.0229519312148164],\n",
        "       [ 0.0122496129390416,  0.8593336968945723,  0.0832280691632935],\n",
        "       [ 0.0337647180964701,  0.9420079681117887,  0.0352795511087547],\n",
        "       [ 0.0235962432976932,  0.9188854350727971,  0.0472252856086054],\n",
        "       [ 0.0384710336609822,  0.9459488329635827,  0.0275422496638241],\n",
        "       [ 0.0623324550915369,  0.9618641277018888,  0.0176722056653054],\n",
        "       [ 0.0256362584332769,  0.9220673859859787,  0.0408438474776337],\n",
        "       [ 0.0000396899464491,  0.041354610567022 ,  0.9758254826491626],\n",
        "       [ 0.0000663051463535,  0.0658293070981806,  0.9617989656992102],\n",
        "       [ 0.0000787150128755,  0.0776409714793461,  0.9538524324283832],\n",
        "       [ 0.0000730790021399,  0.0761134657893654,  0.9614926622256306],\n",
        "       [ 0.0000473704254853,  0.0495934243407565,  0.9717299426507492],\n",
        "       [ 0.000048063048823 ,  0.0507899423895123,  0.9707698581460134],\n",
        "       [ 0.0000724419122068,  0.0694839968887534,  0.9610563839596984],\n",
        "       [ 0.0000693296784629,  0.0722911597425684,  0.9612116838816182],\n",
        "       [ 0.0000539459576919,  0.0542915663835138,  0.9654943489680735],\n",
        "       [ 0.0000689032078452,  0.0740057095920159,  0.9649992933997746],\n",
        "       [ 0.0007294978305257,  0.3696713185724133,  0.68042426467797  ],\n",
        "       [ 0.0000993019568262,  0.0908825094537496,  0.9393447447596552],\n",
        "       [ 0.0001289812502159,  0.1139267479864198,  0.9245464248147172],\n",
        "       [ 0.0000519299964125,  0.0510341083827523,  0.9672949999924123],\n",
        "       [ 0.0000453675570225,  0.0447877935969288,  0.9717037605558507],\n",
        "       [ 0.0000963259675285,  0.0918578001986289,  0.9477923873445283],\n",
        "       [ 0.0001555657824005,  0.1400150676776655,  0.921572721189453 ],\n",
        "       [ 0.0000906989543107,  0.1051937993246916,  0.9635470402258531],\n",
        "       [ 0.0000361049917122,  0.0362096443404772,  0.9742641932541378],\n",
        "       [ 0.0001127167461044,  0.0970379077017777,  0.9247093518390498],\n",
        "       [ 0.0000829638265298,  0.0816293972126503,  0.9532607537434573],\n",
        "       [ 0.0000722735427302,  0.070559008619178 ,  0.9599172768390639],\n",
        "       [ 0.0000450327112883,  0.0469119197398624,  0.971290130848721 ],\n",
        "       [ 0.0004667891982266,  0.2684361656142614,  0.731525927720318 ],\n",
        "       [ 0.0001074795515557,  0.1073645053025249,  0.9479212815318521],\n",
        "       [ 0.000227521914093 ,  0.1921751166408994,  0.8934743921393381],\n",
        "       [ 0.0007615835990476,  0.3603811943383168,  0.6274622408898324],\n",
        "       [ 0.0006315781504267,  0.3410049522195418,  0.7150788894599689],\n",
        "       [ 0.0000507900011231,  0.0518825271136237,  0.968826672623936 ],\n",
        "       [ 0.000685183658401 ,  0.3685031515081374,  0.6942286842224037],\n",
        "       [ 0.0000864035358662,  0.0828316798683613,  0.9469081988046529],\n",
        "       [ 0.000895877104699 ,  0.4582080359105656,  0.7058067257022221],\n",
        "       [ 0.0000470098174276,  0.047805169839288 ,  0.9703953141818785],\n",
        "       [ 0.000872385070396 ,  0.4073818014562473,  0.6288536202681423],\n",
        "       [ 0.0000748749181874,  0.0785347631934012,  0.9608349907853305],\n",
        "       [ 0.0000839791453033,  0.0785698511814114,  0.9454226947297604],\n",
        "       [ 0.0000565471248254,  0.0606203288344361,  0.970688475909476 ],\n",
        "       [ 0.0001556254138221,  0.1441189845306464,  0.9271796396798599],\n",
        "       [ 0.0007462881143953,  0.3720707305534216,  0.6771937227040682],\n",
        "       [ 0.0003054795147062,  0.2128580189806133,  0.8290604036457141],\n",
        "       [ 0.0000598983465501,  0.0601634016698667,  0.9640735102837253],\n",
        "       [ 0.0005561251505942,  0.2945105816775157,  0.6838859121765967],\n",
        "       [ 0.0000663051463535,  0.0658293070981806,  0.9617989656992102],\n",
        "       [ 0.0000546014970841,  0.0575608210179225,  0.968954554591576 ],\n",
        "       [ 0.0000563276424947,  0.0582861535083989,  0.9677889208995587],\n",
        "       [ 0.0001561370472767,  0.1259112838655211,  0.9012832800386046],\n",
        "       [ 0.0001321125594064,  0.1081033278442824,  0.9098399569384797],\n",
        "       [ 0.0002481399813277,  0.1852595089150089,  0.8626642350409577],\n",
        "       [ 0.0000789991503984,  0.0823578293849022,  0.962165991975731 ],\n",
        "       [ 0.0001545890437221,  0.1395636996480588,  0.9264292490418135]])"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "print(datetime.datetime.now())\n",
      "ann = NeuralNetLearner((data.X.shape[1], 20, 9), domain, lambda_=0.0000001)\n",
      "print(datetime.datetime.now())\n",
      "model = ann.fit(data.X, data.Y)\n",
      "print(datetime.datetime.now())\n",
      "answer = model(test_X, ret=Orange.classification.Model.Probs)\n",
      "np.set_printoptions(suppress=True, precision=16)\n",
      "fo = open(\"naloga8.csv\", \"wt\")\n",
      "\n",
      "counter = 0\n",
      "for l in open(\"test.csv\", \"rt\").read().split('\\n'):\n",
      "    l = l.strip()\n",
      "    if l:\n",
      "        if l.startswith(\"id\"):\n",
      "            fo.write(\"id,Class_1,Class_2,Class_3,Class_4,Class_5,Class_6,Class_7,Class_8,Class_9\\n\")\n",
      "        else:\n",
      "            t = l.split(\",\")\n",
      "            fo.write(\",\".join(t[:1] + [\"%.16f\" % e for e in answer[counter]]) + \"\\n\")\n",
      "            counter = counter+1\n",
      "fo.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def logloss(res):\n",
      "    ll = []\n",
      "    for i in range(res.probabilities.shape[0]):\n",
      "        # x je vektor verjetnosti, ki smo jih napovedali dejanskemu razredu\n",
      "        x = np.array([v[i] for v, i in zip(res.probabilities[i], res.actual.astype(int))])\n",
      "        ll.append(-sum(np.log(x))/len(x))\n",
      "    return ll\n",
      "res = Orange.evaluation.CrossValidation(iris_dbg_data, [ann], k=5)\n",
      "logloss(res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  1.  2.]\n",
        "USPELO"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.  1.  2.]\n",
        "USPELO"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.  1.  2.]\n",
        "USPELO"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.  1.  2.]\n",
        "USPELO"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.  1.  2.]\n",
        "USPELO"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "[0.14636846995291611]"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fo = open(\"naloga6.csv\", \"wt\")\n",
      "\n",
      "counter = 0\n",
      "for l in open(\"test.csv\", \"rt\").read().split('\\n'):\n",
      "    l = l.strip()\n",
      "    if l:\n",
      "        if l.startswith(\"id\"):\n",
      "            fo.write(\"id,Class_1,Class_2,Class_3,Class_4,Class_5,Class_6,Class_7,Class_8,Class_9\\n\")\n",
      "        else:\n",
      "            t = l.split(\",\")\n",
      "            fo.write(\",\".join(t[:1] + [\"%.16f\" % e for e in answer[counter]]) + \"\\n\")\n",
      "            counter = counter+1\n",
      "fo.close()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    }
   ],
   "metadata": {}
  }
 ]
}