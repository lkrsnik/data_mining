{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "#%matplotlib inline\n",
      "from scipy.stats.stats import pearsonr\n",
      "from scipy.optimize import fmin_l_bfgs_b\n",
      "from sklearn import cross_validation, preprocessing\n",
      "from collections import defaultdict\n",
      "import Orange\n",
      "from scoring import *\n",
      "\n",
      "class DataPrep:\n",
      "    def legend(fn):\n",
      "        with open(fn) as f:\n",
      "            for l in f:\n",
      "                vals_legend = l.strip().split('\\t')[6:]\n",
      "                return vals_legend\n",
      "            \n",
      "    # read train set\n",
      "    def fix_dilution(s):\n",
      "        return s.replace('\"', '').strip()\n",
      "\n",
      "    def load_data(fn):\n",
      "        readings = defaultdict(list)\n",
      "        with open(fn) as f:\n",
      "            vals_legend = next(f).strip().split('\\t')[6:]\n",
      "            for l in f:\n",
      "                l = l.strip()\n",
      "                t = l.split('\\t')\n",
      "                cid, dilution, vals, intensity = t[0], DataPrep.fix_dilution(t[4]), list(map(float, t[6:])), t[3]\n",
      "                readings[cid, intensity, dilution].append(vals)\n",
      "        for a,b in readings.items():\n",
      "            readings[a] = np.array(b)\n",
      "        return dict(readings)\n",
      "\n",
      "    def mean_indv_notnan(data):\n",
      "        means = []\n",
      "        #average non-nan elements\n",
      "        for vals in data.T:\n",
      "            nonnan = vals[~np.isnan(vals)]\n",
      "            means.append(np.mean(nonnan))\n",
      "        return np.array(means)\n",
      "\n",
      "    def load_data_mean_indv(fn):\n",
      "        readings = DataPrep.load_data(fn)\n",
      "        r2 = {}\n",
      "        for a,b in readings.items():\n",
      "            r2[a] = DataPrep.mean_indv_notnan(np.array(b))\n",
      "        return r2\n",
      "\n",
      "class IO:\n",
      "    # get learning data\n",
      "    def readData(fileName):\n",
      "        test_set = []\n",
      "        with open(fileName) as f:\n",
      "            i = 0\n",
      "            for l in f:\n",
      "                cid, dilution = l.strip().split('\\t')\n",
      "                test_set = np.concatenate((test_set, [cid]))\n",
      "                i += 1\n",
      "            return test_set\n",
      "\n",
      "    def exportResults(writeFileName, ids, legend, results):\n",
      "        results = results.clip(min=0)\n",
      "        i = 0\n",
      "        with open(\"input\", \"wt\") as fi:\n",
      "            with open(writeFileName, \"wt\") as fo:\n",
      "                for l in ids:\n",
      "                    cid = int(l[0])\n",
      "                    fi.write(\"%s\\t%s\\n\" % (cid, l[1]))\n",
      "                    for j in range(results.shape[0]):\n",
      "                        fo.write(\"%s\\t%s\\t%f\\n\" % (cid, legend[j], results[j,i]))\n",
      "                    i += 1\n",
      "    def exportResults2(readFileName, writeFileName, legend, results):\n",
      "        results = results.clip(min=0)\n",
      "        with open(readFileName) as f:\n",
      "            with open(writeFileName, \"wt\") as fo:\n",
      "                i = 0\n",
      "                for l in f:\n",
      "                    cid, dilution = l.strip().split('\\t')\n",
      "                    for j in range(results.shape[0]):\n",
      "                        fo.write(\"%s\\t%s\\t%f\\n\" % (cid, legend[j], results[j,i]))\n",
      "                    i += 1\n",
      "\n",
      "class PipeData:\n",
      "    # returns lines with data\n",
      "    def indexes_array(array, value):\n",
      "        b = (array[:,0]==int(value))\n",
      "        indexes = [i for i in range(len(b)) if b[i]]\n",
      "        if indexes == []:\n",
      "            print (\"NOT GOOD\")\n",
      "            return indexes\n",
      "        return array[indexes[0],:]\n",
      "\n",
      "    def concatenate_array(descriptors, key, dilution, value_X, value_dilution, value_Y=[], value=[], train=False):\n",
      "        res = PipeData.indexes_array(descriptors, key)\n",
      "        if (not(np.isnan(res).any())):\n",
      "            value_X = np.concatenate((value_X, res))\n",
      "            value_Y = np.concatenate((value_Y, value))\n",
      "            value_dilution = np.concatenate((value_dilution, [(key, dilution)])) if len(value_dilution) > 0 else [(key, dilution)]\n",
      "        else:\n",
      "            if (not(train)):\n",
      "                value_X = np.concatenate((value_X, np.zeros(len(res))))\n",
      "        return value_X, value_Y, value_dilution\n",
      "\n",
      "    def create_train_set(train_set, descriptors):\n",
      "        intensity_X = []\n",
      "        intensity_Y = []\n",
      "        intensity_dulition = np.array([])\n",
      "        rest_X = []\n",
      "        rest_Y = []\n",
      "        rest_dulition = []\n",
      "        for key, value in train_set.items():\n",
      "            \n",
      "            if key[2] == \"1/1,000\":\n",
      "                intensity_X, intensity_Y, intensity_dulition = PipeData.concatenate_array(descriptors, key[0], key[2], intensity_X, intensity_dulition, intensity_Y, [value[0]], True)\n",
      "                #intensity_dulition = np.concatenate((intensity_dulition, [(key[0], key[2])])) if len(intensity_dulition) > 0 else [(key[0], key[2])]\n",
      "            if key[1] == \"high \":\n",
      "                rest_X, rest_Y, rest_dulition = PipeData.concatenate_array(descriptors, key[0], key[2], rest_X, rest_dulition, rest_Y, value[1:], True)\n",
      "                #rest_dulition = np.concatenate((rest_dulition, [(key[0], key[2])])) if len(rest_dulition)>0 else [(key[0], key[2])]\n",
      "\n",
      "        intensity_X = intensity_X.reshape((len(intensity_X)/descriptors.shape[1]),descriptors.shape[1])\n",
      "        rest_X = rest_X.reshape((len(rest_X)/descriptors.shape[1]),descriptors.shape[1])\n",
      "        rest_Y = rest_Y.reshape((len(rest_Y)/20),20)\n",
      "        return intensity_X, intensity_Y, intensity_dulition, rest_X, rest_Y, rest_dulition\n",
      "\n",
      "    def create_test_set(test_set, descriptors):\n",
      "        test_X = []\n",
      "        i = 0\n",
      "        for key in test_set:\n",
      "            i += 1\n",
      "            test_X, nothing = PipeData.concatenate_array(descriptors, key, test_X)\n",
      "\n",
      "        test_X = test_X.reshape((len(test_X)/descriptors.shape[1]),descriptors.shape[1])\n",
      "        return test_X\n",
      "\n",
      "def normalize_2(X):\n",
      "    for i in range(X.shape[1]):\n",
      "        if (sum(X[:, i]) > 0 and np.std(X[:, i]) > 0.00001):\n",
      "            #print (sum(X[:, i]))\n",
      "            X[:, i]=X[:, i]-(sum(X[:, i])/X.shape[1])/np.std(X[:, i])\n",
      "            if np.isinf(X[:, i]).any():\n",
      "                print (i)\n",
      "                print (np.std(X[:, i]))\n",
      "                print (X[:, i])\n",
      "        else:\n",
      "            X[:, i]=np.zeros(len(X[:, i]))\n",
      "    return X\n",
      "\n",
      "# calculates a new theta\n",
      "def calculate_model(f, X, y, alpha):\n",
      "    #lr = Orange.regression.LassoRegressionLearner(alpha = alpha, max_iter = 1000, normalize = False) \n",
      "    #linearna regresija L2 - lr je objekt, ki se ucije metoda, ki pricakuje podatke\n",
      "    #y=y-(sum(y)/(len(y)))/np.std(y)\n",
      "    lr = f(alpha) #linearna regresija L2 - lr je objekt, ki se ucije metoda, ki pricakuje podatke\n",
      "    new_table = Orange.data.Table(X, y)\n",
      "    \n",
      "    model = lr(new_table)\n",
      "    return model\n",
      "\n",
      "\n",
      "# where the magic happens\n",
      "def magic(descriptors, train_set, test_set, alpha):\n",
      "    # formats train and test set\n",
      "    intensity_X, intensity_Y, rest_X, rest_Y = PipeData.create_train_set(train_set, descriptors)\n",
      "    test_X = PipeData.create_test_set(test_set, descriptors)\n",
      "\n",
      "    # calculates intensity\n",
      "    intensity_model = calculate_model(intensity_X, intensity_Y, alpha)\n",
      "    intensity_result = intensity_model(test_X)\n",
      "\n",
      "    # calculates others\n",
      "    rest_result = []\n",
      "    for i in range(rest_Y.shape[1]):\n",
      "        rest_model = calculate_model(rest_X, rest_Y[:,i], alpha)\n",
      "        rest_result = np.concatenate((rest_result, rest_model(test_X)))\n",
      "    rest_result = rest_result.reshape((len(rest_result)/len(intensity_result)),len(intensity_result))\n",
      "\n",
      "    # stacks and export results\n",
      "    return np.vstack((intensity_result, rest_result))\n",
      "\n",
      "def preprocess_cross_validation(j, intensity_X, intensity_Y, intensity_dulition, k, localized):\n",
      "    #print (intensity_X.shape, intensity_Y.shape, intensity_dulition.shape)\n",
      "    low_limit_intensity = int((intensity_X.shape[0] * j) / k)\n",
      "    high_limit_intensity = int((intensity_X.shape[0] * (j + 1)) / k)\n",
      "\n",
      "    new_intensity_X = (intensity_X.T[:, np.concatenate((np.arange(0, low_limit_intensity), np.arange(high_limit_intensity, intensity_X.shape[0])))]).T\n",
      "    new_intensity_Y = (intensity_Y[np.concatenate((np.arange(0, low_limit_intensity), np.arange(high_limit_intensity, intensity_Y.shape[0])))])\n",
      "\n",
      "    new_intensity_test_X = (intensity_X.T[:, range(low_limit_intensity, high_limit_intensity)]).T\n",
      "\n",
      "    if localized:\n",
      "        i = low_limit_intensity\n",
      "        new_intensity_dulition = []\n",
      "        while (i < high_limit_intensity):\n",
      "            new_intensity_dulition = np.concatenate((new_intensity_dulition, [intensity_dulition[i]])) if len(new_intensity_dulition) > 0 else [intensity_dulition[i]]\n",
      "            i += 1\n",
      "    else:\n",
      "        i = 0\n",
      "        new_intensity_dulition = []\n",
      "        while (i < low_limit_intensity or (i >= high_limit_intensity and i < len(intensity_dulition))):\n",
      "            new_intensity_dulition = np.concatenate((new_intensity_dulition, [intensity_dulition[i]])) if len(new_intensity_dulition) > 0 else [intensity_dulition[i]]\n",
      "            i += 1\n",
      "        i = high_limit_intensity\n",
      "        while (i < len(intensity_dulition)):\n",
      "            new_intensity_dulition = np.concatenate((new_intensity_dulition, [intensity_dulition[i]])) if len(new_intensity_dulition) > 0 else [intensity_dulition[i]]\n",
      "            i += 1\n",
      "\n",
      "    return new_intensity_X, new_intensity_Y, new_intensity_test_X, new_intensity_dulition\n",
      "\n",
      "def custom_cross_validation(f, p, intensity_X, intensity_Y, intensity_dulition, k, intensity, localized = True):\n",
      "    intensity_result_F = []\n",
      "    rest_result_F = []\n",
      "    for j in range(k):\n",
      "        i = 0\n",
      "        new_intensity_X, new_intensity_Y, new_intensity_test_X, new_intensity_dulition = preprocess_cross_validation(j, intensity_X, intensity_Y, intensity_dulition, k, localized)\n",
      "        if intensity:\n",
      "            if localized:\n",
      "                intensity_model = calculate_model(f, new_intensity_X, new_intensity_Y, p)\n",
      "            else:\n",
      "                intensity_model = f(new_intensity_X, new_intensity_Y, new_intensity_dulition, intensity)\n",
      "            intensity_result = intensity_model(new_intensity_test_X)\n",
      "            intensity_result = np.vstack((intensity_result, np.zeros((20, len(intensity_result)))))\n",
      "\n",
      "        # calculates others\n",
      "        if not intensity:\n",
      "            if not localized:\n",
      "                intensity_model = f(new_intensity_X, new_intensity_Y, new_intensity_dulition, intensity)\n",
      "            intensity_result = []\n",
      "            for i in range(intensity_Y.shape[1]):\n",
      "                if localized:\n",
      "                    intensity_model = calculate_model(f, new_intensity_X, new_intensity_Y[:,i], p)\n",
      "                    intensity_result = np.concatenate((intensity_result, intensity_model(new_intensity_test_X)))\n",
      "                else:\n",
      "                    intensity_result = np.concatenate((intensity_result, (intensity_model[i])(new_intensity_test_X)))\n",
      "            intensity_result = intensity_result.reshape(20, (len(intensity_result) / 20))\n",
      "            intensity_result = np.vstack((np.zeros((intensity_result.shape[1])), intensity_result))\n",
      "\n",
      "        intensity_result_F = np.concatenate((intensity_result_F.T, intensity_result.T)).T if len(intensity_result_F) > 0 else intensity_result\n",
      "    return intensity_result_F\n",
      "\n",
      "class PFit:\n",
      "    def __init__(self, learner, ps):\n",
      "        self.l = learner\n",
      "        self.ps = ps\n",
      "    def __call__(self, intensity_X, intensity_Y, intensity_dulition, intensity = True):\n",
      "        best_p = 0\n",
      "        best_score = 0\n",
      "        for p in self.ps:\n",
      "            intensity_result_F = custom_cross_validation(self.l, p, intensity_X, intensity_Y, intensity_dulition, k_in, intensity, True)\n",
      "            IO.exportResults(\"output\", intensity_dulition, legend, intensity_result_F)\n",
      "            fscore = score(legend)\n",
      "            if fscore > best_score:\n",
      "                best_score = fscore\n",
      "                best_p = p\n",
      "\n",
      "        if intensity:\n",
      "            return calculate_model(self.l, intensity_X, intensity_Y, p)\n",
      "\n",
      "        if not intensity:\n",
      "            all_models = []\n",
      "            for i in range(intensity_Y.shape[1]):\n",
      "                all_models = np.concatenate((all_models, [calculate_model(self.l, intensity_X, intensity_Y[:,i], p)])) if len(all_models) > 0 else [calculate_model(self.l, intensity_X, intensity_Y[:,i], p)]\n",
      "            return all_models\n",
      "        \n",
      "        \n",
      "\n",
      "cross_validation = True \n",
      "alpha = 0.8\n",
      "k_in = 2\n",
      "k_out = 10\n",
      "alphas = [5]\n",
      "\n",
      "# reading data\n",
      "train_set = DataPrep.load_data_mean_indv(\"TrainSet-hw2.txt\")\n",
      "legend = DataPrep.legend(\"TrainSet-hw2.txt\")\n",
      "descriptors = Orange.data.Table(\"molecular_descriptors_data.txt\").X\n",
      "#where_are_NaNs = np.isnan(descriptors)\n",
      "#descriptors[where_are_NaNs] = 0\n",
      "#descriptors = descriptors[:, np.min(descriptors, axis=0) != np.max(descriptors, axis=0)]\n",
      "#print (descriptors.shape)\n",
      "\n",
      "test_set = IO.readData(\"predict.txt\")\n",
      "\n",
      "# writes data for scoring.py\n",
      "#with open(\"input\", \"wt\") as fo:\n",
      "#    for el in train_set:\n",
      "#        fo.write(\"%s\\t%s\\n\" % (el[0], el[1]))\n",
      "\n",
      "# only for learning on data\n",
      "intensity_X, intensity_Y, intensity_dulition ,rest_X, rest_Y, rest_dulition = PipeData.create_train_set(train_set, descriptors)\n",
      "\n",
      "#lassoPreprocess = PFit(Orange.regression.linear.LassoRegressionLearner, alphas)\n",
      "#lassoPreprocess(intensity_X, intensity_Y, intensity_dulition)\n",
      "#lassoPreprocess(rest_X, rest_Y, rest_dulition, False)\n",
      "#print (score(legend))\n",
      "    \n",
      "# -------------------------- OUTER CROSS VALIDATION\n",
      "def lasso(parameter):\n",
      "    return Orange.regression.linear.LassoRegressionLearner(alpha = parameter)\n",
      "\n",
      "lassoPreprocess = PFit(lasso, alphas)\n",
      "\n",
      "print (\" ----------------------- LASSO -------------------\")\n",
      "lasso_int_res = custom_cross_validation(lassoPreprocess, alphas, intensity_X, intensity_Y, intensity_dulition, k_out, True, False)\n",
      "IO.exportResults(\"output\", intensity_dulition, legend, lasso_int_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL INTENSITY: \")\n",
      "print (fscore)\n",
      "\n",
      "lasso_res_res = custom_cross_validation(lassoPreprocess, alphas, rest_X, rest_Y, rest_dulition, k_out, False, False)\n",
      "IO.exportResults(\"output\", rest_dulition, legend, lasso_res_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL REST: \")\n",
      "print (fscore)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ----------------------- LASSO -------------------\n",
        "FINAL INTENSITY: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.00762945495\n",
        "FINAL REST: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.3809384191\n"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas = [20000]\n",
      "\n",
      "def ridge(parameter):\n",
      "    return Orange.regression.linear.RidgeRegressionLearner(alpha = parameter)\n",
      "\n",
      "ridgePreprocess = PFit(ridge, alphas)\n",
      "\n",
      "print (\" ------------------------ RIDGE --------------------- \")\n",
      "\n",
      "ridge_int_res = custom_cross_validation(ridgePreprocess, alphas, intensity_X, intensity_Y, intensity_dulition, k_out, True, False)\n",
      "IO.exportResults(\"output\", intensity_dulition, legend, ridge_int_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL INTENSITY: \")\n",
      "print (fscore)\n",
      "\n",
      "ridge_res_res = custom_cross_validation(ridgePreprocess, alphas, rest_X, rest_Y, rest_dulition, k_out, False, False)\n",
      "IO.exportResults(\"output\", rest_dulition, legend, ridge_res_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL REST: \")\n",
      "print (fscore)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ------------------------ RIDGE --------------------- \n",
        "FINAL INTENSITY: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.01076083061\n",
        "FINAL REST: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.33412612441\n"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas = [1]\n",
      "\n",
      "def elastic(parameter):\n",
      "    return Orange.regression.linear.ElasticNetLearner(alpha = parameter)\n",
      "\n",
      "elasticPreprocess = PFit(elastic, alphas)\n",
      "\n",
      "print (\" ------------------------ ELASTIC --------------------- \")\n",
      "\n",
      "elastic_int_res = custom_cross_validation(elasticPreprocess, alphas, intensity_X, intensity_Y, intensity_dulition, k_out, True, False)\n",
      "IO.exportResults(\"output\", intensity_dulition, legend, elastic_int_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL INTENSITY: \")\n",
      "print (fscore)\n",
      "\n",
      "elastic_res_res = custom_cross_validation(elasticPreprocess, alphas, rest_X, rest_Y, rest_dulition, k_out, False, False)\n",
      "IO.exportResults(\"output\", rest_dulition, legend, elastic_res_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL REST: \")\n",
      "print (fscore)\n",
      "print (\"Over!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ------------------------ ELASTIC --------------------- \n",
        "FINAL INTENSITY: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.786259537353\n",
        "FINAL REST: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.42312295918\n",
        "Over!\n"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas = [100]\n",
      "\n",
      "def random_forest(parameter):\n",
      "    return Orange.classification.SimpleRandomForestLearner()\n",
      "\n",
      "forestPreprocess = PFit(random_forest, alphas)\n",
      "\n",
      "print (\" ------------------- RANDOM FOREST ------------------- \")\n",
      "\n",
      "forest_int_res = custom_cross_validation(forestPreprocess, alphas, intensity_X, intensity_Y, intensity_dulition, k_out, True, False)\n",
      "IO.exportResults(\"output\", intensity_dulition, legend, forest_int_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL INTENSITY: \")\n",
      "print (fscore)\n",
      "\n",
      "forest_res_res = custom_cross_validation(forestPreprocess, alphas, rest_X, rest_Y, rest_dulition, k_out, False, False)\n",
      "IO.exportResults(\"output\", rest_dulition, legend, forest_res_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL REST: \")\n",
      "print (fscore)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ------------------- RANDOM FOREST ------------------- \n",
        "FINAL INTENSITY: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.961998816574\n",
        "FINAL REST: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.71024604165\n"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas = [5]\n",
      "\n",
      "def knn(parameter):\n",
      "    return Orange.regression.KNNRegressionLearner()\n",
      "\n",
      "knnPreprocess = PFit(knn, alphas)\n",
      "\n",
      "print (\" ------------------- KNN LEARNER ------------------- \")\n",
      "\n",
      "knn_int_res = custom_cross_validation(knnPreprocess, alphas, intensity_X, intensity_Y, intensity_dulition, k_out, True, False)\n",
      "IO.exportResults(\"output\", intensity_dulition, legend, knn_int_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL INTENSITY: \")\n",
      "print (fscore)\n",
      "\n",
      "knn_res_res = custom_cross_validation(knnPreprocess, alphas, rest_X, rest_Y, rest_dulition, k_out, False, False)\n",
      "IO.exportResults(\"output\", rest_dulition, legend, knn_res_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL REST: \")\n",
      "print (fscore)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ------------------- KNN LEARNER ------------------- \n",
        "FINAL INTENSITY: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.717759561324\n",
        "FINAL REST: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.1541330496\n"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas = [2000]\n",
      "\n",
      "def linear_regression(parameter):\n",
      "    return Orange.regression.linear.LinearRegressionLearner()\n",
      "\n",
      "linearPreprocess = PFit(linear_regression, alphas)\n",
      "\n",
      "print (\" ------------------- LINEAR REGRESSION ------------------- \")\n",
      "\n",
      "lin_int_res = custom_cross_validation(linearPreprocess, alphas, intensity_X, intensity_Y, intensity_dulition, k_out, True, False)\n",
      "IO.exportResults(\"output\", intensity_dulition, legend, lin_int_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL INTENSITY: \")\n",
      "print (fscore)\n",
      "\n",
      "lin_res_res = custom_cross_validation(linearPreprocess, alphas, rest_X, rest_Y, rest_dulition, k_out, False, False)\n",
      "IO.exportResults(\"output\", rest_dulition, legend, lin_res_res)\n",
      "fscore = score(legend)\n",
      "print (\"FINAL REST: \")\n",
      "print (fscore)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ------------------- LINEAR REGRESSION ------------------- \n",
        "FINAL INTENSITY: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0864822827607\n",
        "FINAL REST: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.12800577349\n"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ----------------- MEAN -------------------------\n",
      "print (\" ------------------- MEAN ------------------- \")\n",
      "mean_int_res = (lasso_int_res + ridge_int_res + elastic_int_res + forest_int_res + knn_int_res + lin_int_res) / 6\n",
      "IO.exportResults(\"output\", intensity_dulition, legend, mean_int_res)\n",
      "fscore = score(legend)\n",
      "print (\"MEAN INTENSITY: \")\n",
      "print (fscore)\n",
      "\n",
      "mean_int_res = (lasso_res_res + ridge_res_res + elastic_res_res + forest_res_res + knn_res_res + lin_res_res) / 6\n",
      "IO.exportResults(\"output\", intensity_dulition, legend, mean_int_res)\n",
      "fscore = score(legend)\n",
      "print (\"MEAN REST: \")\n",
      "print (fscore)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ------------------- MEAN ------------------- \n",
        "MEAN INTENSITY: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.795594069436\n",
        "MEAN REST: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.206839130624\n"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ---------------- STACKING -------------------\n",
      "print (\" ----------------- STACKING ----------------- \")\n",
      "intensity_matrix = np.vstack((lasso_int_res[0, :], ridge_int_res[0, :], elastic_int_res[0, :], forest_int_res[0, :], knn_int_res[0, :], lin_int_res[0, :]))\n",
      "\n",
      "ridge_stack = Orange.regression.linear.RidgeRegressionLearner()\n",
      "data = Orange.data.Table(intensity_matrix.T, intensity_Y)\n",
      "intensity_model = ridge_stack(data)\n",
      "\n",
      "\n",
      "all_models = []\n",
      "for i in range(1,21):\n",
      "    rest_matrix = np.vstack((lasso_res_res[i, :], ridge_res_res[i, :], elastic_res_res[i, :], forest_res_res[i, :], knn_res_res[i, :], lin_res_res[i, :]))\n",
      "    \n",
      "    data = Orange.data.Table(rest_matrix.T, rest_Y[:,i-1])\n",
      "    model = ridge_stack(data)\n",
      "    all_models = np.concatenate((all_models, [model])) if len(all_models) > 0 else [model]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ----------------- STACKING ----------------- \n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def concatenate_array(descriptors, key, value_X, value_Y=[], value=[], train=False):\n",
      "    res = PipeData.indexes_array(descriptors, key)\n",
      "    if (not(np.isnan(res).any())):\n",
      "        value_X = np.concatenate((value_X, res))\n",
      "        value_Y = np.concatenate((value_Y, value))\n",
      "    else:\n",
      "        if (not(train)):\n",
      "            value_X = np.concatenate((value_X, np.zeros(len(res))))\n",
      "    return value_X, value_Y\n",
      "\n",
      "def create_test_set(test_set, descriptors):\n",
      "    test_X = []\n",
      "    i = 0\n",
      "    for key in test_set:\n",
      "        i += 1\n",
      "        test_X, nothing = concatenate_array(descriptors, key, test_X)\n",
      "\n",
      "    test_X = test_X.reshape((len(test_X)/descriptors.shape[1]),descriptors.shape[1])\n",
      "    return test_X\n",
      "\n",
      "\n",
      "# --------------------------------- GET ALL TEST DATA ----------------------------------\n",
      "print (rest_Y.shape[1])\n",
      "print (test_X.shape)\n",
      "test_X = create_test_set(test_set, descriptors)\n",
      "\n",
      "def calculate_algorithm_intensity(f, p):\n",
      "    lass = f(p)\n",
      "    data = Orange.data.Table(intensity_X, intensity_Y)\n",
      "    model = lass(data)\n",
      "    return model(test_X)\n",
      "\n",
      "def calculate_algorithm_rest(f, p):\n",
      "    lass = f(p)\n",
      "    \n",
      "    rest_result = []\n",
      "    for i in range(rest_Y.shape[1]):\n",
      "        data = Orange.data.Table(intensity_X, intensity_Y)\n",
      "        model = lass(data)\n",
      "        rest_result = np.concatenate((rest_result, model(test_X)))\n",
      "    rest_result = rest_result.reshape((len(rest_result)/rest_Y.shape[1]),rest_Y.shape[1])\n",
      "    return rest_result\n",
      "\n",
      "las_int = calculate_algorithm_intensity(lasso, 5)\n",
      "las_res = calculate_algorithm_rest(lasso, 5)\n",
      "\n",
      "\n",
      "#intensity_result = intensity_model(test_X)\n",
      "#for i in range(all_models.shape[0]):\n",
      "#    rest_result = np.concatenate((rest_result, all_models[i](test_X)))\n",
      "#rest_result = rest_result.reshape((len(rest_result)/len(intensity_result)),len(intensity_result))\n",
      "#np.vstack((intensity_result, rest_result))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20\n",
        "(80, 4870)\n"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rid_int = calculate_algorithm_intensity(ridge, 20000)\n",
      "rid_res = calculate_algorithm_rest(ridge, 20000)\n",
      "\n",
      "ela_int = calculate_algorithm_intensity(elastic, 1)\n",
      "ela_res = calculate_algorithm_rest(elastic, 1)\n",
      "\n",
      "for_int = calculate_algorithm_intensity(random_forest, 100)\n",
      "for_res = calculate_algorithm_rest(random_forest, 100)\n",
      "\n",
      "knn_int = calculate_algorithm_intensity(knn, 5)\n",
      "knn_res = calculate_algorithm_rest(knn, 5)\n",
      "\n",
      "lin_int = calculate_algorithm_intensity(linear_regression, 2000)\n",
      "lin_res = calculate_algorithm_rest(linear_regression, 2000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def exportResults2(readFileName, writeFileName, legend, results):\n",
      "    results = results.clip(min=0)\n",
      "    with open(readFileName) as f:\n",
      "        with open(writeFileName, \"wt\") as fo:\n",
      "            i = 0\n",
      "            for l in f:\n",
      "                cid, dilution = l.strip().split('\\t')\n",
      "                for j in range(results.shape[0]):\n",
      "                    fo.write(\"%s\\t%s\\t%f\\n\" % (cid, legend[j], results[j,i]))\n",
      "                i += 1\n",
      "\n",
      "intensity_test = np.vstack((las_int, rid_int, ela_int, for_int, knn_int, lin_int))\n",
      "intensity_result = intensity_model(intensity_test.T)\n",
      "\n",
      "rest_finnal = []\n",
      "for i in range(las_res.shape[1]):\n",
      "    rest_test = np.vstack((las_res.T[i, :], rid_res.T[i, :], ela_res.T[i, :], for_res.T[i, :], knn_res.T[i, :], lin_res.T[i, :]))\n",
      "    rest_column = (all_models[i])(rest_test.T)\n",
      "    rest_finnal = np.concatenate((rest_finnal, [rest_column])) if len(rest_finnal) > 0 else [rest_column]\n",
      "   \n",
      "finnal = np.vstack((intensity_result, rest_finnal))\n",
      "\n",
      "exportResults2(\"predict.txt\", \"result\", legend, finnal)\n",
      "fscore = score(legend)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    }
   ],
   "metadata": {}
  }
 ]
}