{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "from scipy.optimize import fmin_l_bfgs_b\n",
      "import Orange"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Classes And Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class IO:\n",
      "    def read(fn, train=True):\n",
      "        X = np.genfromtxt(fn, delimiter = ',', usecols = np.arange(0, 93), skiprows = 1, dtype = float)\n",
      "        # converts first line into int and saves it\n",
      "        ids = X[:, 0].copy().astype(int)\n",
      "        # changes first line to ones\n",
      "        X[:, 0] = np.ones(X.shape[0])\n",
      "        if(train):\n",
      "            y = np.genfromtxt(fn, delimiter = ',', usecols = {94}, skiprows = 1, dtype = str)\n",
      "            # converts classes from string to float numbers\n",
      "            yn = np.zeros(len(y))\n",
      "            i = 0\n",
      "            for el in y:\n",
      "                yn[i] = float(el[6])\n",
      "                i += 1   \n",
      "            y = yn\n",
      "            return X, y\n",
      "        else:\n",
      "            return X, ids\n",
      "    def write(res, ids):\n",
      "        fc = np.hstack((['id'], ids))\n",
      "        oc = np.vstack((['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9'], res))\n",
      "        sres = np.column_stack((fc, oc))\n",
      "        np.savetxt('results.csv', sres, delimiter=\",\", fmt=\"%s\") \n",
      "class LogicalRegression:\n",
      "    def __init__(self, lam):\n",
      "        self.lam = lam\n",
      "    def __call__(self, X, y):\n",
      "        init_theta = np.zeros(X.shape[1]).T\n",
      "        return fmin_l_bfgs_b(LogicalRegression.cost, init_theta, LogicalRegression.gradient, args=(X, y, self.lam))[0]\n",
      "    def sigmoid(theta, x):\n",
      "        return 1. / (1 + np.exp(-x.dot(theta)))\n",
      "    \n",
      "    #gradient for compution in l_bfsg\n",
      "    def gradient(theta, X, y, lam):\n",
      "        h = LogicalRegression.sigmoid(theta, X)\n",
      "        g1 = (1. / X.shape[0]) * (h - y).T.dot(X[:, 0])\n",
      "        g2 = (1. / X.shape[0]) * (((h - y).dot(X[:, 1:X.shape[1]])) + lam * theta[1:])\n",
      "        return np.hstack((g1, g2)).T\n",
      "\n",
      "    #cost function for compution in l_bfsg\n",
      "    def cost(theta, X, y, lam):\n",
      "        h = LogicalRegression.sigmoid(theta, X)\n",
      "        return (1. / X.shape[0]) * ((-y.T.dot(np.log(h + 1e-10) )) - (1 - y.T).dot(np.log(1. - h + 1e-10))) + (lam / (2. * X.shape[0])) * (theta[1:].T.dot(theta[1:]))\n",
      "    \n",
      "class OneVsAll:\n",
      "    def __init__(self, f):\n",
      "        self.f = f\n",
      "    def __call__(self, X, y):\n",
      "        t = []\n",
      "        # all classes\n",
      "        c = np.unique(y)\n",
      "        # changes specific class to 1 and others to 0\n",
      "        for el in c:\n",
      "            yn = y.copy()\n",
      "            yn[y == el] = 1\n",
      "            yn[y != el] = 0\n",
      "            t = np.append(t, self.f(X, yn))\n",
      "        return t.reshape((len(t) / X.shape[1]), X.shape[1])\n",
      "    \n",
      "class OneVsOne:\n",
      "    def __init__(self, f):\n",
      "        self.f = f\n",
      "    def __call__(self, X, y):\n",
      "        t = []\n",
      "        # all classes\n",
      "        c = np.unique(y)\n",
      "        # changes specific class to 1 and others to 0\n",
      "        for i in range(len(c) - 1):\n",
      "            for j in range(i + 1, len(c)):\n",
      "                #print (j)\n",
      "                yn = y.copy()\n",
      "                # finds elements in array for this comparison for later vector/matrix cut\n",
      "                cut = np.logical_or(yn == c[i], yn == c[j])\n",
      "                # sets desirable elements to 0 or 1\n",
      "                yn[y == c[i]] = 1\n",
      "                yn[y == c[j]] = 0\n",
      "                yn = yn[cut]\n",
      "                Xn = X[cut]\n",
      "                t = np.append(t, self.f(Xn, yn))\n",
      "        #return t\n",
      "        return t.reshape((len(t) / ((len(c) * (len(c) - 1)) / 2)), (len(c) * (len(c) - 1)) / 2)\n",
      "    def result(ovor, l):\n",
      "        res = np.zeros((ovor.shape[0], l))\n",
      "        k = 0\n",
      "        for i in range(l - 1):\n",
      "            for j in range(i + 1, l):\n",
      "                fc = ovor[:,k].copy()\n",
      "                fc[ovor[:,k] > 0.5] = 1\n",
      "                fc[ovor[:,k] <= 0.5] = 0\n",
      "                lc = ovor[:,k].copy()\n",
      "                lc[ovor[:,k] > 0.5] = 0\n",
      "                lc[ovor[:,k] <= 0.5] = 1\n",
      "                res[:,i] = res[:,i] + fc\n",
      "                res[:,j] = res[:,j] + lc\n",
      "                k += 1\n",
      "        return res / ovor.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "One vs All"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = IO.read('train.csv')\n",
      "lam = 0.01\n",
      "lr = LogicalRegression(lam)\n",
      "ova = OneVsAll(lr)\n",
      "thetas = ova(X, y)\n",
      "Xt, ids = IO.read('test.csv', False)\n",
      "# calculate results on test data\n",
      "res = LogicalRegression.sigmoid(thetas.T, Xt)\n",
      "IO.write(res, ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "One vs One"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = IO.read('train.csv')\n",
      "lam = 0.01\n",
      "lr = LogicalRegression(lam)\n",
      "ovo = OneVsOne(lr)\n",
      "thetas = ovo(X, y)\n",
      "Xt, ids = IO.read('test.csv', False)\n",
      "# calculate results on test data\n",
      "ovor = LogicalRegression.sigmoid(thetas, Xt)\n",
      "res = OneVsOne.result(ovor, len(np.unique(y)))\n",
      "IO.write(res, ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Numerical gradient"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def numerical_grad(f, params, epsilon):\n",
      "    num_grad = np.zeros(len(params))\n",
      "    perturb = np.zeros(len(params))\n",
      "    for i in range(params.size):\n",
      "        perturb[i] = epsilon\n",
      "        j1 = f(params + perturb)\n",
      "        j2 = f(params - perturb)\n",
      "        num_grad[i] = (j1 - j2) / (2. * epsilon)\n",
      "        perturb[i] = 0\n",
      "    return num_grad\n",
      "\n",
      "#X = np.array([[2,2],[1,3],[2,1],[4,1],[3,3],[2,4]])\n",
      "#y = np.array([0]*3+[1]*3)\n",
      "#X = np.random.rand(1000, 7)\n",
      "#y = (np.random.rand(1000)>0.3).astype(int)\n",
      "#X = np.vstack((np.ones(X.shape[0]), X.T)).T\n",
      "init_theta = np.zeros(X.shape[1])\n",
      "\n",
      "\n",
      "ag = LogicalRegression.gradient(init_theta, X, y, 0.01)\n",
      "ng = numerical_grad(lambda params: LogicalRegression.cost(params, X, y, 0.01), init_theta, 1e-4)\n",
      "print(np.sum((ag - ng)**2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4.24330352419e-16\n"
       ]
      }
     ],
     "prompt_number": 40
    }
   ],
   "metadata": {}
  }
 ]
}